{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Deep ML using Convolutional Neural Network using Tensorflow\n",
    "\n",
    "References: \n",
    "\n",
    "* [Tensorflow Tutorial](https://www.tensorflow.org/versions/master/get_started/mnist/pros)\n",
    "\n",
    "MNIST is a simple computer vision dataset. It consists of images of handwritten digits like these:\n",
    "\n",
    "![](https://www.tensorflow.org/images/MNIST.png)\n",
    "\n",
    "IN this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"A deep MNIST classifier using convolutional layers.\n",
    "\n",
    "See extensive documentation at\n",
    "https://www.tensorflow.org/get_started/mnist/pros\n",
    "\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data import \n",
    "\n",
    "The MNIST data is hosted on [this website](http://yann.lecun.com/exdb/mnist/). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Import Data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST data is split into three parts: \n",
    "\n",
    "1. 55,000 data points of training data (`mnist.train`), \n",
    "2. 10,000 points of test data (`mnist.test`), \n",
    "3. 5,000 points of validation data (`mnist.validation`). \n",
    "\n",
    "This split is very important: it's of course essential in ML that we have separate data which we don't learn from so that we can make sure that what we've learned actually generalizes!\n",
    "\n",
    "Each image is 28 pixels by 28 pixels. We can interpret this as a big array of numbers:\n",
    "\n",
    "![](https://www.tensorflow.org/images/MNIST-Matrix.png)\n",
    "\n",
    "Thus after flattening the image into vectors of 28*28=784, we obtain as `mnist.train.images` a tensor (an n-dimensional array) with a shape of [55000, 784]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model creation\n",
    "\n",
    "MNIST images is of a handwritten digit between zero and nine. So there are only ten possible things that a given image can be. \n",
    "We want to be able to look at an image and give the probabilities for it being each digit, thus base on Softmax Regressions as activation function. `softmax()` has the advantage of allowing for an easy mapping to a probability (as sum = 1) and thus can be used a nice last layout of the ML process. \n",
    "\n",
    "* See also [List of activation function](https://en.wikipedia.org/wiki/Activation_function#Comparison_of_activation_functions)\n",
    "\n",
    "A softmax regression has two steps: \n",
    "\n",
    "1. first we add up the evidence of our input image being in certain classes. For that, we do a weighted sum of the pixel intensities $y=W*x+b$, where the weight is negative if that pixel having a high intensity is evidence against the image being in that class, and positive if it is evidence in favor. \n",
    "2. and then we convert that evidence into probabilities throught the application of the `softmax()` function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "x  = tf.placeholder(tf.float32, [None, 784])  # Placeholder for the input images\n",
    "\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])   # Placeholder to input the **correct** answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Deep Neural Network\n",
    "\n",
    "We are going to use a more sophisticated model than the simple one previously: a small convolutional neural network.\n",
    "\n",
    "![](https://www.tensorflow.org/images/mnist_deep.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full code implementing the above graph is given below.\n",
    "From bottom to top, the following steps are defined: \n",
    "\n",
    "* `reshape` step: to use within a convolutional neural net, to reshape input grayscale 28x28 images. The last dimension is for \"features\" - there is only one here, since images are grayscale -- it would be 3 for an RGB image, 4 for RGBA, etc.\n",
    "* `conv1`, the first convolutional layer, maps one grayscale image to 32 feature maps\n",
    "* `pool1`, the first Pooling layer - downsamples by 2X.\n",
    "* `conv2`, the second convolutional layer -- maps 32 feature maps to 64.\n",
    "* `pool2`, the second Pooling layer\n",
    "* `fc1`, the Densely Connected Layer / Fully connected layer 1 -- after 2 round of downsampling, our 28x28 image is down to 7x7x64 feature maps -- maps this to 1024 features.\n",
    "* `dropout` step, extremely important to reduce overfitting, controls the complexity of the model, prevents co-adaptation of features.\n",
    "* Finally, we add a readout layer called `fc2`, just like for the one layer softmax regression of the simple example, responsible to map the 1024 features to 10 classes, one for each digit\n",
    "\n",
    "Further xplainations for some design choices follows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def deepnn(x):\n",
    "  \"\"\"deepnn builds the graph for a deep net for classifying digits.\n",
    "  Args:\n",
    "    x: an input tensor with the dimensions (N_examples, 784), where 784 is the\n",
    "    number of pixels in a standard MNIST image.\n",
    "  Returns:\n",
    "    A tuple (y, keep_prob). y is a tensor of shape (N_examples, 10), with values\n",
    "    equal to the logits of classifying the digit into one of 10 classes (the\n",
    "    digits 0-9). keep_prob is a scalar placeholder for the probability of\n",
    "    dropout.\n",
    "  \"\"\"\n",
    "  # Reshape to use within a convolutional neural net.\n",
    "  # Last dimension is for \"features\" - there is only one here, since images are\n",
    "  # grayscale -- it would be 3 for an RGB image, 4 for RGBA, etc.\n",
    "  with tf.name_scope('reshape'):\n",
    "    x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "\n",
    "  # First convolutional layer - maps one grayscale image to 32 feature maps.\n",
    "  with tf.name_scope('conv1'):\n",
    "    W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "    b_conv1 = bias_variable([32])\n",
    "    h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "\n",
    "  # Pooling layer - downsamples by 2X.\n",
    "  with tf.name_scope('pool1'):\n",
    "    h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "  # Second convolutional layer -- maps 32 feature maps to 64.\n",
    "  with tf.name_scope('conv2'):\n",
    "    W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "    b_conv2 = bias_variable([64])\n",
    "    h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "\n",
    "  # Second pooling layer.\n",
    "  with tf.name_scope('pool2'):\n",
    "    h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "  # Fully connected layer 1 -- after 2 round of downsampling, our 28x28 image\n",
    "  # is down to 7x7x64 feature maps -- maps this to 1024 features.\n",
    "  with tf.name_scope('fc1'):\n",
    "    W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "    b_fc1 = bias_variable([1024])\n",
    "\n",
    "    h_pool2_flat = tf.reshape(h_pool2, [-1, 7 * 7 * 64])\n",
    "    h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "  # Dropout - controls the complexity of the model, prevents co-adaptation of\n",
    "  # features.\n",
    "  with tf.name_scope('dropout'):\n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "    h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "  # Map the 1024 features to 10 classes, one for each digit\n",
    "  with tf.name_scope('fc2'):\n",
    "    W_fc2 = weight_variable([1024, 10])\n",
    "    b_fc2 = bias_variable([10])\n",
    "\n",
    "    y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "  return y_conv, keep_prob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Toolbox function\n",
    "\n",
    "To create this model, we're going to need to create a lot of weights and biases. Yet \n",
    "\n",
    "* weight should generally be initialized with a small amount of noise for symmetry breaking, and to prevent 0 gradients. \n",
    "* as regards bias, since [ReLU](https://en.wikipedia.org/wiki/Rectifier_(neural_networks)) neurons will be used, it is also good practice to initialize them with a slightly positive initial bias to avoid \"dead neurons\". \n",
    "\n",
    "Instead of doing this repeatedly while we build the model, let's create two handy functions to do it for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "  \"\"\"weight_variable generates a weight variable of a given shape.\"\"\"\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "  \"\"\"bias_variable generates a bias variable of a given shape.\"\"\"\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow also gives a lot of flexibility in convolution and pooling operations. How do we handle the boundaries? What is our stride size? In this example, we're always going to choose the vanilla version yet provide these through the following functions:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "  \"\"\"conv2d returns a 2d convolution layer with full stride.\"\"\"\n",
    "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "  \"\"\"max_pool_2x2 downsamples a feature map by 2X.\"\"\"\n",
    "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the graph and the deep network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_conv, keep_prob = deepnn(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function, Training and Evaluation\n",
    "\n",
    "How well does this model do? To train and evaluate it we will use code that is nearly identical to that for the simple one layer SoftMax network above. In particular, we will still rely on the \"cross-entropy\" as  a _loss_ function expected to be minimized $H_{y'}(y\\_conv) = -\\sum_i y'_i \\log(y\\_conv_i) = -\\sum y' \\log(y\\_conv)$ (where $y\\_conv$ is our predicted probability distribution, and $y′$ is the true distribution), yet still in its numerically stable version i.e. `tf.nn.softmax_cross_entropy_with_logits` on the raw outputs of 'y_conv', and then average across the batch.\n",
    "\n",
    "The differences are that:\n",
    "\n",
    "* We will replace the steepest gradient descent optimizer with the more sophisticated ADAM optimizer.\n",
    "* We will include the additional parameter keep_prob in feed_dict to control the dropout rate and thus reduce the overfitting\n",
    "* We will add logging to every 100th iteration in the training process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The raw formulation of cross-entropy,\n",
    "#\n",
    "#   tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(tf.nn.softmax(y_conv)),\n",
    "#                                 reduction_indices=[1]))\n",
    "#\n",
    "# can be numerically unstable.\n",
    "#\n",
    "# So here we use tf.nn.softmax_cross_entropy_with_logits on the raw\n",
    "# outputs of 'y', and then average across the batch.\n",
    "with tf.name_scope('loss'):\n",
    "    cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_,\n",
    "                                                                           logits=y_conv))\n",
    "# Training\n",
    "with tf.name_scope('adam_optimizer'):\n",
    "    train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "\n",
    "# Stepwise accuracy computation\n",
    "with tf.name_scope('accuracy'):\n",
    "    correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
    "    correct_prediction = tf.cast(correct_prediction, tf.float32)\n",
    "    accuracy = tf.reduce_mean(correct_prediction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's go\n",
    "\n",
    "We will use `tf.Session` rather than `tf.InteractiveSession`. This better separates the process of creating the graph (model specification) and the process of evaluating the graph (model fitting). \n",
    "It generally makes for cleaner code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.06\n",
      "step 1000, training accuracy 1\n",
      "step 2000, training accuracy 0.94\n",
      "step 3000, training accuracy 0.98\n",
      "step 4000, training accuracy 0.98\n",
      "step 5000, training accuracy 1\n",
      "step 6000, training accuracy 1\n",
      "step 7000, training accuracy 0.96\n",
      "step 8000, training accuracy 1\n",
      "step 9000, training accuracy 1\n",
      "step 10000, training accuracy 1\n",
      "step 11000, training accuracy 1\n",
      "step 12000, training accuracy 0.98\n",
      "step 13000, training accuracy 1\n",
      "step 14000, training accuracy 1\n",
      "step 15000, training accuracy 1\n",
      "step 16000, training accuracy 1\n",
      "step 17000, training accuracy 1\n",
      "step 18000, training accuracy 0.98\n",
      "step 19000, training accuracy 1\n",
      "test accuracy 0.9925\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(20000):\n",
    "      batch = mnist.train.next_batch(50)\n",
    "      if i % 1000 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={\n",
    "            x: batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "        print('step %d, training accuracy %g' % (i, train_accuracy))\n",
    "      train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "\n",
    "    print('test accuracy %g' % accuracy.eval(feed_dict={\n",
    "        x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That means and accuracy of around 99.25%, which is way better than the previously obtained results (around 92%) when the [best models](https://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results) allow for 99.79% of accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sc17",
   "language": "python",
   "name": "sc17"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
